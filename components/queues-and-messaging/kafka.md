---
description: >-
  Discover more about the Kafka component and how to use it on the Digibee
  Integration Platform.
---

# Kafka

**Kafka** produces records to the Kafka brokers configured in it.    &#x20;

## Parameters

Take a look at the configuration parameters of the component. Parameters supported by [Double Braces expressions](https://docs.digibee.com/documentation/build/double-braces) are marked with `(DB)`.

<table data-full-width="true"><thead><tr><th width="182">Parameter</th><th width="338">Description</th><th width="133.75">Default value</th><th>Data type</th></tr></thead><tbody><tr><td><strong>Kafka Authentication Account</strong></td><td>If the Kafka server needs authentication, it will be necessary to create an account type Basic for this component. We also support authentication via Kerberos.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Truststore</strong></td><td>If it’s necessary to inform a truststore to make the SSL Handshake using private certificates, a Certificate Chain type account must be created, and the concatenated certificates must be informed. It’s optional to inform the password to be registered in the truststore creation, in the password field.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Keystore</strong></td><td>If it’s necessary to inform a keystore to make the mutual SSL authentication, a Certificate Chain type account must be created, the complete chain with the concatenated certificates and the private key to be used for the SSL mutual authentication must be informed. If there’s a private key, it’s necessary to inform it in the password field.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Brokers</strong></td><td>Brokers of the server (HOST: PORT) used to send registers. To inform multiple HOSTS, you can separate them by comma. Example: HOST1:PORT1,HOST2:PORT2,...,HOSTn:PORTn</td><td>N/A</td><td>String</td></tr><tr><td><strong>Security Protocol</strong></td><td>The way the connection is established. It's optional to use a security channel (SSL) and an authentication channel (SASL). The use of both (SASL_SSL) is also possible.</td><td>SSL</td><td>String</td></tr><tr><td><strong>Topic Name</strong></td><td>Kafka's topic name.</td><td>{{ DEFAULT(message.topic, "new-topic") }}</td><td>String</td></tr><tr><td><strong>Schema Registry URL</strong></td><td>If at least one of the options <strong>Headers By Avro Schema, Payload As Avro</strong>, and Partition Key As Avro is enabled, the field will be shown to configure the Schema Registry's URL.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Schema Registry Account</strong></td><td>Account to authenticate with Schema Registry.</td><td>N/A</td><td>N/A</td></tr><tr><td><strong>Schema Registry Truststore</strong></td><td>If it’s necessary to inform a truststore to make the SSL Handshake using private certificates, a Certificate Chain type account must be created, and the concatenated certificates must be informed. It’s optional to inform the password to be registered in the truststore creation, in the password field.</td><td>N/A</td><td>N/A</td></tr><tr><td><strong>Schema Registry Keystore</strong></td><td>If it’s necessary to inform a keystore to make the mutual SSL authentication, a Certificate Chain type account must be created, the complete chain with the concatenated certificates and the private key to be used for the SSL mutual authentication must be informed. If there’s a private key, it’s necessary to inform it in the password field.</td><td>N/A</td><td>N/A</td></tr><tr><td><strong>Headers</strong></td><td>Set of key-value inputs, with headers to be sent in the message (optional field).</td><td>N/A</td><td>Key-value</td></tr><tr><td><strong>Binary Headers</strong></td><td>If the option is active, the header values are considered binary and are interpreted as a string with the base64 representation; otherwise, the header values are interpreted as text.</td><td>False</td><td>Boolean</td></tr><tr><td><strong>Headers By Avro Schema</strong></td><td>If the option is active, the component will validate the Headers based on an Avro Schema before sending the Headers.</td><td>False</td><td>Boolean</td></tr><tr><td><strong>Headers Schema</strong></td><td>If the option <strong>Headers By Avro Schema</strong> is active, the field will be shown to set the Headers Schemas to be validated.</td><td>N/A</td><td>N/A</td></tr><tr><td><strong>Headers Charset</strong></td><td>Name of the character's code for the header values codification (standard UTF-8).</td><td>UTF-8</td><td>String</td></tr><tr><td><strong>Payload</strong></td><td>Payload to be dispatched.</td><td>{{ message.$ }}</td><td>String</td></tr><tr><td><strong>Payload As Avro</strong></td><td>If the option is active, the component will send the payload in Avro format.</td><td>False</td><td>Boolean</td></tr><tr><td><strong>Payload Schema</strong></td><td>This field is available only if the option <strong>Payload As Avro</strong> is active and informs the Payload Schema to be validated.</td><td>N/A</td><td>N/A</td></tr><tr><td><strong>Request Timeout</strong></td><td>Configuration that controls the maximum time (in milliseconds) that the client waits for the response of an inquiry. If the response isn't received before the maximum time elapses, the inquiry is automatically resent. Otherwise, there'll be an error if the retries are exhausted.</td><td>60000</td><td>Integer</td></tr><tr><td><strong>Retries</strong></td><td>If a value different than 0 (zero) is established, any register whose dispatch fails will be resent. These registers might be resent with a probable transient error.</td><td>N/A</td><td>Integer</td></tr><tr><td><strong>Metadata Timeout</strong></td><td>Maximum time to the Kafka register dispatch.</td><td>5000</td><td>Integer</td></tr><tr><td><strong>Key Strategy</strong></td><td>If the option <strong>Partition Key As Avro</strong> is active, the field will be shown to inform the subject to be used to construct the subject name for message keys.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Value Strategy</strong></td><td>If the option <strong>Payload as Avro</strong> is enabled, the field will be shown to inform the subject to be used to construct the subject name for message values.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Fail On Error</strong></td><td>If the option is active, the execution of the pipeline with error will be interrupted; otherwise, the pipeline execution proceeds, but the result will show a false value for the “success” property.</td><td>False</td><td>Boolean</td></tr><tr><td><strong>Advanced Settings</strong></td><td>If the option is active, you can access the following configurations:</td><td>False</td><td>Boolean</td></tr><tr><td><strong>Kerberos Service Name</strong></td><td>Value defined in the <strong>sasl.kerberos.service.name</strong> property configured in the Kafka broker server side.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Partition Number</strong></td><td>Specifies the numbers of the partition where <a href="../triggers/kafka-trigger.md"><strong>Kafka Trigger</strong></a> will send the messages to. If the property isn’t configured, the Kafka server will be responsible for deciding which topic partition the message will be sent to.</td><td>N/A</td><td>Integer</td></tr><tr><td><strong>Partition Key</strong></td><td>A partition key can be specified to indicate the partition where the message will be sent to. If the field isn’t filled, a partitioner based on hashing is used to determine the partition id given to each key.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Partition Key As Avro</strong></td><td>If the option is enabled, the component will send the partition key in Avro format.</td><td>N/A</td><td>Boolean</td></tr><tr><td><strong>Partition Key Schema</strong></td><td>If the option <strong>Partition Key As Avro</strong> is active, the field will be shown to inform the Partition Key Schema to be validated.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Producer Client Name</strong></td><td>Origin identifier of the requests (optional).</td><td>N/A</td><td>String</td></tr><tr><td><strong>ACKS</strong></td><td>Configuration for acknowledging the message receipt by the Kafka broker (values: 0, 1, or ALL).</td><td>1</td><td>Integer</td></tr><tr><td><strong>Use Dynamic Account</strong></td><td>When the option is active, the account will be used dynamically. Set the account name to allow for flexible usage. When deactivated, the account name will be static.</td><td>False</td><td>Boolean</td></tr><tr><td><strong>Account Name</strong></td><td>The name of the Basic account that is generated dynamically via the <a href="https://docs.digibee.com/documentation/components/tools/store-account"><strong>Store Account component</strong></a>.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Scoped</strong></td><td>When the option is active, the stored account is isolated to other sub-process. In that case, sub-processes will see their own version of the stored account data.</td><td>N/A</td><td>Boolean</td></tr><tr><td><strong>Truststore Account Name</strong></td><td>The name of the truststore account that is generated dynamically via the <strong>Store Account</strong> component. Supported accounts: Certificate Chain.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Keystore Account Name</strong></td><td>The name of the keystore account that is generated dynamically via the <strong>Store Account</strong> component. Supported accounts: Certificate Chain.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Account Name for Registry</strong></td><td>The name of the account for the registry that is generated dynamically via the <strong>Store Account</strong> component. Supported accounts: Basic or Oauth Bearer Token.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Truststore Account Name for Registry</strong></td><td>The name of the truststore account for the registry that is generated dynamically via the <strong>Store Account</strong> component. Supported accounts: Certificate Chain.</td><td>N/A</td><td>String</td></tr><tr><td><strong>Keystore Account Name for Registry</strong></td><td>The name of the keystore account for the registry that is generated dynamically via the <strong>Store Account</strong> component. Supported accounts: Certificate Chain.</td><td>N/A</td><td>String</td></tr></tbody></table>

{% hint style="info" %}
**Important information:**&#x20;

* Due to the need of a great memory allocation, we don't support the following types of Security Protocol: PLAINTEXT and SASL\_PLAINTEXT. For more information, [visit the external Apache Kafka documentation](https://cwiki.apache.org/confluence/display/KAFKA/KIP-498%3A+Add+client-side+configuration+for+maximum+response+size+to+protect+against+OOM).
* The messages sent in Avro format must be of the maximum size supported by Pipelines SMALL, MEDIUM and LARGE. The component does not support extreme reading scenarios of mega/giga/tera/peta bytes. The Avro format support is currently in Beta phase.
* Currently, the **Use Dynamic Account,** **Account Name**, **Scoped**, **Truststore Account Name**, **Keystore Account Name**, **Account Name for Registry**, **Truststore Account Name for Registry**, and **Keystore Account Name for Registry** parameters can only be used in Pipeline Engine v2 and are only available in the Restricted Beta phase. To learn more about it,[ read the article Beta program](https://docs.digibee.com/documentation/general/beta-program)
{% endhint %}

## Example of request response to Kafka  <a href="#example-of-request-response-to-kafka" id="example-of-request-response-to-kafka"></a>

```
{
  "message": "{}",
  "offset": 201,
  "timestamp": 1585168528773,
  "serializedKeySize": -1,
  "serializedValueSize": 2,
  "topic": "Welcome-Kafka",
  "partition": 1,
  "success": true
}
```

* **message:** message sent.
* **offset:** offset of the record in the topic/partition.
* **timestamp:** time stamp of the record in the topic/partition.
* **serializedKeySize:** size of the serialized key, uncompressed in bytes. If the value is null, the returned size is -1.
* **serializedValueSize:** size of the serialized value, uncompressed in bytes. If the value is null, the returned size is -1.
* **topic:** name of the topic.
* **partition:** partition the record was sent to.
* **success:** if "true", the dispatch was successfully made.       &#x20;

## Messages flow <a href="#messages-flow" id="messages-flow"></a>

### Input <a href="#input" id="input"></a>

The component accepts any input message and can use it through Double Braces.

### Output <a href="#output" id="output"></a>

The component doesn't change any information of the input message. Therefore, it's returned to the following component or it's used as final answer if this component is the last step of the pipeline.&#x20;

## Kafka in Action <a href="#kafka-in-action" id="kafka-in-action"></a>

### Authentication using SSL or SASL <a href="#authentication-using-ssl-or-sasl" id="authentication-using-ssl-or-sasl"></a>

That allows the authentication of your producers and clients to the Kafka cluster (identity verification). This is also a secure way to allow your clients to confirm their identity.

### Authentication using Kerberos <a href="#authentication-using-kerberos" id="authentication-using-kerberos"></a>

To use the authentication via Kerberos in **Kafka** is necessary to have registered the configuration file “krb5.conf” in the Realm parameter. If you haven't done it yet, get in touch with us by the chat service. After finishing this step, all you have to do is to correctly set a Kerberos-type account and use it in the component.
